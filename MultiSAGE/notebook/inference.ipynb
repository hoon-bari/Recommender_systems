{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import dgl\n",
    "\n",
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dgl.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the apply_train data\n",
    "apply_train_df = pd.read_csv('/path/to/apply_train.csv')\n",
    "grouped_apply_train = apply_train_df.groupby('resume_seq')['recruitment_seq'].apply(list)\n",
    "\n",
    "# Load the resume and recruitment vectors\n",
    "resume_vector = np.load('/path/to/h_resume.npz')\n",
    "recruitment_vector = np.load('/path/to/h_recruitment.npz')\n",
    "\n",
    "h_resume = resume_vector['resume_vectors']\n",
    "h_recruitment = recruitment_vector['recruitment_vectors']\n",
    "\n",
    "# Create a FAISS index for the recruitment vectors\n",
    "index = faiss.IndexFlatL2(h_recruitment.shape[1])\n",
    "index.add(h_recruitment)\n",
    "\n",
    "# Load the sample_submission DataFrame\n",
    "sample_submission_df = pd.read_csv('/path/to/sample_submission.csv')\n",
    "\n",
    "# Prepare the submission DataFrame\n",
    "submission_dict = {'resume_seq': [], 'recruitment_seq': []}\n",
    "\n",
    "# Iterate over the resume sequences in the sample submission\n",
    "for resume_id in sample_submission_df['resume_seq'].unique():\n",
    "    query_vector = h_resume[int(resume_id[1:]) - 1]  # Assuming the ID follows the 'Uxxxxx' format\n",
    "    applied_jobs = grouped_apply_train.get(resume_id, [])\n",
    "    \n",
    "    # Search for the top 5+length of applied jobs similar vectors\n",
    "    D, I = index.search(query_vector.reshape(1, -1), 5 + len(applied_jobs))\n",
    "    \n",
    "    # Filter out the applied jobs and prepare the recommendation in the required format\n",
    "    recommended_jobs = ['R' + str(idx + 1).zfill(5) for idx in I[0] if idx not in applied_jobs][:5]\n",
    "    \n",
    "    # Add the recommendations to the submission_dict\n",
    "    for job_id in recommended_jobs:\n",
    "        submission_dict['resume_seq'].append(resume_id)\n",
    "        submission_dict['recruitment_seq'].append(job_id)\n",
    "\n",
    "# Create a new DataFrame for the submission\n",
    "final_submission_df = pd.DataFrame(submission_dict)\n",
    "\n",
    "# Save the final submission\n",
    "final_submission_df.to_csv('/path/to/final_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
