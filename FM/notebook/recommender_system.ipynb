{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall5(answer_df, submission_df):\n",
    "    \"\"\"\n",
    "    Calculate recall@5 for given dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    - answer_df: DataFrame containing the ground truth\n",
    "    - submission_df: DataFrame containing the predictions\n",
    "    \n",
    "    Returns:\n",
    "    - recall: Recall@5 value\n",
    "    \"\"\"\n",
    "    \n",
    "    primary_col = answer_df.columns[0]\n",
    "    secondary_col = answer_df.columns[1]\n",
    "    \n",
    "    # Check if each primary_col entry has exactly 5 secondary_col predictions\n",
    "    prediction_counts = submission_df.groupby(primary_col).size()\n",
    "    if not all(prediction_counts == 5):\n",
    "        raise ValueError(f\"Each {primary_col} should have exactly 5 {secondary_col} predictions.\")\n",
    "\n",
    "\n",
    "    # Check for NULL values in the predicted secondary_col\n",
    "    if submission_df[secondary_col].isnull().any():\n",
    "        raise ValueError(f\"Predicted {secondary_col} contains NULL values.\")\n",
    "    \n",
    "    # Check for duplicates in the predicted secondary_col for each primary_col\n",
    "    duplicated_preds = submission_df.groupby(primary_col).apply(lambda x: x[secondary_col].duplicated().any())\n",
    "    if duplicated_preds.any():\n",
    "        raise ValueError(f\"Predicted {secondary_col} contains duplicates for some {primary_col}.\")\n",
    "\n",
    "\n",
    "    # Filter the submission dataframe based on the primary_col present in the answer dataframe\n",
    "    submission_df = submission_df[submission_df[primary_col].isin(answer_df[primary_col])]\n",
    "    \n",
    "    # For each primary_col, get the top 5 predicted secondary_col values\n",
    "    top_5_preds = submission_df.groupby(primary_col).apply(lambda x: x[secondary_col].head(5).tolist()).to_dict()\n",
    "    \n",
    "    # Convert the answer_df to a dictionary for easier lookup\n",
    "    true_dict = answer_df.groupby(primary_col).apply(lambda x: x[secondary_col].tolist()).to_dict()\n",
    "    \n",
    "    \n",
    "    individual_recalls = []\n",
    "    for key, val in true_dict.items():\n",
    "        if key in top_5_preds:\n",
    "            correct_matches = len(set(true_dict[key]) & set(top_5_preds[key]))\n",
    "            individual_recall = correct_matches / min(len(val), 5) # 공정한 평가를 가능하게 위하여 분모(k)를 'min(len(val), 5)' 로 설정함 \n",
    "            individual_recalls.append(individual_recall)\n",
    "\n",
    "\n",
    "    recall = np.mean(individual_recalls)\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from src.generate_neg_samples import generate_negative_samples_of_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {'SEED' : 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_train = pd.read_csv('./Data/apply_train.csv')\n",
    "resume_data = pd.read_csv('./Data/resume_for_cosine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>resume_seq</th>\n",
       "      <th>U00001</th>\n",
       "      <th>U00002</th>\n",
       "      <th>U00003</th>\n",
       "      <th>U00004</th>\n",
       "      <th>U00005</th>\n",
       "      <th>U00006</th>\n",
       "      <th>U00007</th>\n",
       "      <th>U00008</th>\n",
       "      <th>U00009</th>\n",
       "      <th>U00010</th>\n",
       "      <th>...</th>\n",
       "      <th>U08473</th>\n",
       "      <th>U08474</th>\n",
       "      <th>U08475</th>\n",
       "      <th>U08476</th>\n",
       "      <th>U08477</th>\n",
       "      <th>U08478</th>\n",
       "      <th>U08479</th>\n",
       "      <th>U08480</th>\n",
       "      <th>U08481</th>\n",
       "      <th>U08482</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resume_seq</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U00001</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484995</td>\n",
       "      <td>0.648015</td>\n",
       "      <td>0.520206</td>\n",
       "      <td>0.539193</td>\n",
       "      <td>0.436084</td>\n",
       "      <td>0.367257</td>\n",
       "      <td>0.552206</td>\n",
       "      <td>0.532357</td>\n",
       "      <td>0.431512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548405</td>\n",
       "      <td>0.496440</td>\n",
       "      <td>0.589285</td>\n",
       "      <td>0.576954</td>\n",
       "      <td>0.536866</td>\n",
       "      <td>0.640190</td>\n",
       "      <td>0.434560</td>\n",
       "      <td>0.450777</td>\n",
       "      <td>0.610337</td>\n",
       "      <td>0.378312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U00002</th>\n",
       "      <td>0.484995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.418616</td>\n",
       "      <td>0.425232</td>\n",
       "      <td>0.308574</td>\n",
       "      <td>0.690865</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>0.502984</td>\n",
       "      <td>0.435338</td>\n",
       "      <td>0.744270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404757</td>\n",
       "      <td>0.694373</td>\n",
       "      <td>0.590405</td>\n",
       "      <td>0.490450</td>\n",
       "      <td>0.490014</td>\n",
       "      <td>0.487568</td>\n",
       "      <td>0.487372</td>\n",
       "      <td>0.645143</td>\n",
       "      <td>0.514630</td>\n",
       "      <td>0.295726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U00003</th>\n",
       "      <td>0.648015</td>\n",
       "      <td>0.418616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657585</td>\n",
       "      <td>0.377308</td>\n",
       "      <td>0.518786</td>\n",
       "      <td>0.302322</td>\n",
       "      <td>0.627550</td>\n",
       "      <td>0.570646</td>\n",
       "      <td>0.464603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.386414</td>\n",
       "      <td>0.676765</td>\n",
       "      <td>0.564506</td>\n",
       "      <td>0.567766</td>\n",
       "      <td>0.676061</td>\n",
       "      <td>0.367384</td>\n",
       "      <td>0.341040</td>\n",
       "      <td>0.542344</td>\n",
       "      <td>0.231229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U00004</th>\n",
       "      <td>0.520206</td>\n",
       "      <td>0.425232</td>\n",
       "      <td>0.657585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569777</td>\n",
       "      <td>0.480298</td>\n",
       "      <td>0.296397</td>\n",
       "      <td>0.677025</td>\n",
       "      <td>0.579019</td>\n",
       "      <td>0.578286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581899</td>\n",
       "      <td>0.448977</td>\n",
       "      <td>0.673056</td>\n",
       "      <td>0.615703</td>\n",
       "      <td>0.527101</td>\n",
       "      <td>0.775396</td>\n",
       "      <td>0.379692</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>0.691692</td>\n",
       "      <td>0.379286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U00005</th>\n",
       "      <td>0.539193</td>\n",
       "      <td>0.308574</td>\n",
       "      <td>0.377308</td>\n",
       "      <td>0.569777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270664</td>\n",
       "      <td>0.287039</td>\n",
       "      <td>0.505810</td>\n",
       "      <td>0.399549</td>\n",
       "      <td>0.321392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456360</td>\n",
       "      <td>0.422399</td>\n",
       "      <td>0.447150</td>\n",
       "      <td>0.533152</td>\n",
       "      <td>0.456519</td>\n",
       "      <td>0.538655</td>\n",
       "      <td>0.309154</td>\n",
       "      <td>0.288872</td>\n",
       "      <td>0.519360</td>\n",
       "      <td>0.602154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U08478</th>\n",
       "      <td>0.640190</td>\n",
       "      <td>0.487568</td>\n",
       "      <td>0.676061</td>\n",
       "      <td>0.775396</td>\n",
       "      <td>0.538655</td>\n",
       "      <td>0.488876</td>\n",
       "      <td>0.405332</td>\n",
       "      <td>0.691890</td>\n",
       "      <td>0.641802</td>\n",
       "      <td>0.593306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596049</td>\n",
       "      <td>0.507024</td>\n",
       "      <td>0.845071</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.641644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488023</td>\n",
       "      <td>0.406924</td>\n",
       "      <td>0.708952</td>\n",
       "      <td>0.343332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U08479</th>\n",
       "      <td>0.434560</td>\n",
       "      <td>0.487372</td>\n",
       "      <td>0.367384</td>\n",
       "      <td>0.379692</td>\n",
       "      <td>0.309154</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>0.509269</td>\n",
       "      <td>0.464245</td>\n",
       "      <td>0.387918</td>\n",
       "      <td>0.345776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406253</td>\n",
       "      <td>0.368173</td>\n",
       "      <td>0.589620</td>\n",
       "      <td>0.394342</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>0.488023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312237</td>\n",
       "      <td>0.513413</td>\n",
       "      <td>0.338471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U08480</th>\n",
       "      <td>0.450777</td>\n",
       "      <td>0.645143</td>\n",
       "      <td>0.341040</td>\n",
       "      <td>0.349301</td>\n",
       "      <td>0.288872</td>\n",
       "      <td>0.595620</td>\n",
       "      <td>0.563254</td>\n",
       "      <td>0.468059</td>\n",
       "      <td>0.499638</td>\n",
       "      <td>0.647525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333548</td>\n",
       "      <td>0.822564</td>\n",
       "      <td>0.409326</td>\n",
       "      <td>0.370689</td>\n",
       "      <td>0.457802</td>\n",
       "      <td>0.406924</td>\n",
       "      <td>0.312237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434852</td>\n",
       "      <td>0.318568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U08481</th>\n",
       "      <td>0.610337</td>\n",
       "      <td>0.514630</td>\n",
       "      <td>0.542344</td>\n",
       "      <td>0.691692</td>\n",
       "      <td>0.519360</td>\n",
       "      <td>0.470188</td>\n",
       "      <td>0.339384</td>\n",
       "      <td>0.705297</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.569289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523261</td>\n",
       "      <td>0.529512</td>\n",
       "      <td>0.659652</td>\n",
       "      <td>0.646871</td>\n",
       "      <td>0.616894</td>\n",
       "      <td>0.708952</td>\n",
       "      <td>0.513413</td>\n",
       "      <td>0.434852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U08482</th>\n",
       "      <td>0.378312</td>\n",
       "      <td>0.295726</td>\n",
       "      <td>0.231229</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>0.602154</td>\n",
       "      <td>0.250162</td>\n",
       "      <td>0.268443</td>\n",
       "      <td>0.401476</td>\n",
       "      <td>0.343432</td>\n",
       "      <td>0.345919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402163</td>\n",
       "      <td>0.491292</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>0.440586</td>\n",
       "      <td>0.390070</td>\n",
       "      <td>0.343332</td>\n",
       "      <td>0.338471</td>\n",
       "      <td>0.318568</td>\n",
       "      <td>0.501862</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8482 rows × 8482 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "resume_seq    U00001    U00002    U00003    U00004    U00005    U00006  \\\n",
       "resume_seq                                                               \n",
       "U00001      1.000000  0.484995  0.648015  0.520206  0.539193  0.436084   \n",
       "U00002      0.484995  1.000000  0.418616  0.425232  0.308574  0.690865   \n",
       "U00003      0.648015  0.418616  1.000000  0.657585  0.377308  0.518786   \n",
       "U00004      0.520206  0.425232  0.657585  1.000000  0.569777  0.480298   \n",
       "U00005      0.539193  0.308574  0.377308  0.569777  1.000000  0.270664   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "U08478      0.640190  0.487568  0.676061  0.775396  0.538655  0.488876   \n",
       "U08479      0.434560  0.487372  0.367384  0.379692  0.309154  0.396491   \n",
       "U08480      0.450777  0.645143  0.341040  0.349301  0.288872  0.595620   \n",
       "U08481      0.610337  0.514630  0.542344  0.691692  0.519360  0.470188   \n",
       "U08482      0.378312  0.295726  0.231229  0.379286  0.602154  0.250162   \n",
       "\n",
       "resume_seq    U00007    U00008    U00009    U00010  ...    U08473    U08474  \\\n",
       "resume_seq                                          ...                       \n",
       "U00001      0.367257  0.552206  0.532357  0.431512  ...  0.548405  0.496440   \n",
       "U00002      0.698196  0.502984  0.435338  0.744270  ...  0.404757  0.694373   \n",
       "U00003      0.302322  0.627550  0.570646  0.464603  ...  0.534759  0.386414   \n",
       "U00004      0.296397  0.677025  0.579019  0.578286  ...  0.581899  0.448977   \n",
       "U00005      0.287039  0.505810  0.399549  0.321392  ...  0.456360  0.422399   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "U08478      0.405332  0.691890  0.641802  0.593306  ...  0.596049  0.507024   \n",
       "U08479      0.509269  0.464245  0.387918  0.345776  ...  0.406253  0.368173   \n",
       "U08480      0.563254  0.468059  0.499638  0.647525  ...  0.333548  0.822564   \n",
       "U08481      0.339384  0.705297  0.563879  0.569289  ...  0.523261  0.529512   \n",
       "U08482      0.268443  0.401476  0.343432  0.345919  ...  0.402163  0.491292   \n",
       "\n",
       "resume_seq    U08475    U08476    U08477    U08478    U08479    U08480  \\\n",
       "resume_seq                                                               \n",
       "U00001      0.589285  0.576954  0.536866  0.640190  0.434560  0.450777   \n",
       "U00002      0.590405  0.490450  0.490014  0.487568  0.487372  0.645143   \n",
       "U00003      0.676765  0.564506  0.567766  0.676061  0.367384  0.341040   \n",
       "U00004      0.673056  0.615703  0.527101  0.775396  0.379692  0.349301   \n",
       "U00005      0.447150  0.533152  0.456519  0.538655  0.309154  0.288872   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "U08478      0.845071  0.631868  0.641644  1.000000  0.488023  0.406924   \n",
       "U08479      0.589620  0.394342  0.489035  0.488023  1.000000  0.312237   \n",
       "U08480      0.409326  0.370689  0.457802  0.406924  0.312237  1.000000   \n",
       "U08481      0.659652  0.646871  0.616894  0.708952  0.513413  0.434852   \n",
       "U08482      0.296028  0.440586  0.390070  0.343332  0.338471  0.318568   \n",
       "\n",
       "resume_seq    U08481    U08482  \n",
       "resume_seq                      \n",
       "U00001      0.610337  0.378312  \n",
       "U00002      0.514630  0.295726  \n",
       "U00003      0.542344  0.231229  \n",
       "U00004      0.691692  0.379286  \n",
       "U00005      0.519360  0.602154  \n",
       "...              ...       ...  \n",
       "U08478      0.708952  0.343332  \n",
       "U08479      0.513413  0.338471  \n",
       "U08480      0.434852  0.318568  \n",
       "U08481      1.000000  0.501862  \n",
       "U08482      0.501862  1.000000  \n",
       "\n",
       "[8482 rows x 8482 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'resume_seq' 컬럼 제외\n",
    "resume_features = resume_data.drop(columns=['resume_seq'])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "cosine_sim = cosine_similarity(resume_features)\n",
    "\n",
    "# 코사인 유사도 결과를 DataFrame으로 변환\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, \n",
    "                             index=resume_data['resume_seq'], \n",
    "                             columns=resume_data['resume_seq'])\n",
    "\n",
    "# 결과 출력 (옵션)\n",
    "cosine_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값을 정의합니다.\n",
    "threshold = 0.26\n",
    "\n",
    "# 유사도가 임계값 이하인 쌍의 인덱스를 찾습니다.\n",
    "low_similarity_pairs = np.column_stack(np.where(cosine_sim_df.values <= threshold))\n",
    "\n",
    "# 각 resume_seq에 대해 지원한 공고의 집합을 만듭니다.\n",
    "resume_to_recruitments = apply_train.groupby('resume_seq')['recruitment_seq'].apply(set).to_dict()\n",
    "\n",
    "# 각 사용자에 대한 negative 후보들의 집합을 준비합니다.\n",
    "negative_candidates_dict = {}\n",
    "for i, j in low_similarity_pairs:\n",
    "    resume_seq_i, resume_seq_j = cosine_sim_df.index[i], cosine_sim_df.index[j]\n",
    "    \n",
    "    # 이미 처리된 이력서를 체크하기 위한 집합을 사용합니다.\n",
    "    processed_resumes = set()\n",
    "    \n",
    "    # 첫 번째 이력서에 대한 negative 후보 업데이트\n",
    "    if resume_seq_i not in processed_resumes:\n",
    "        applied_positions_j = resume_to_recruitments[resume_seq_j]\n",
    "        negative_candidates_dict.setdefault(resume_seq_i, set()).update(applied_positions_j)\n",
    "        processed_resumes.add(resume_seq_i)\n",
    "    \n",
    "    # 두 번째 이력서에 대한 negative 후보 업데이트\n",
    "    if resume_seq_j not in processed_resumes:\n",
    "        applied_positions_i = resume_to_recruitments[resume_seq_i]\n",
    "        negative_candidates_dict.setdefault(resume_seq_j, set()).update(applied_positions_i)\n",
    "        processed_resumes.add(resume_seq_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U00001</td>\n",
       "      <td>[R00827, R05482, R00328, R01201]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U00002</td>\n",
       "      <td>[R04733, R00862, R03700, R05702, R04002, R0619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U00003</td>\n",
       "      <td>[R02763, R06150, R04416]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U00004</td>\n",
       "      <td>[R05995, R01971, R01922, R02401, R05234, R0108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U00005</td>\n",
       "      <td>[R00376, R04672, R01643]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>U08478</td>\n",
       "      <td>[R01795, R06082]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>U08479</td>\n",
       "      <td>[R03632, R06512, R01655, R06386, R02857, R01301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>U08480</td>\n",
       "      <td>[R02634, R03531]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>U08481</td>\n",
       "      <td>[R02569, R02217, R04470]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>U08482</td>\n",
       "      <td>[R04999, R04935, R02439]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     resume_seq                          recruitment_seq_negatives\n",
       "0        U00001                   [R00827, R05482, R00328, R01201]\n",
       "1        U00002  [R04733, R00862, R03700, R05702, R04002, R0619...\n",
       "2        U00003                           [R02763, R06150, R04416]\n",
       "3        U00004  [R05995, R01971, R01922, R02401, R05234, R0108...\n",
       "4        U00005                           [R00376, R04672, R01643]\n",
       "...         ...                                                ...\n",
       "8477     U08478                                   [R01795, R06082]\n",
       "8478     U08479   [R03632, R06512, R01655, R06386, R02857, R01301]\n",
       "8479     U08480                                   [R02634, R03531]\n",
       "8480     U08481                           [R02569, R02217, R04470]\n",
       "8481     U08482                           [R04999, R04935, R02439]\n",
       "\n",
       "[8482 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 병렬 처리를 위한 tasks 리스트를 준비합니다.\n",
    "tasks = [(resume_seq, candidates, resume_to_recruitments) for resume_seq, candidates in negative_candidates_dict.items()]\n",
    "\n",
    "# 병렬 처리를 설정합니다.\n",
    "with Pool(processes=4) as pool:\n",
    "    # pool.starmap을 사용하여 각 함수 호출에 여러 인자를 전달합니다.\n",
    "    results = pool.starmap(generate_negative_samples_of_user, tasks)\n",
    "\n",
    "# 결과를 정리합니다.\n",
    "negative_samples = list(results)\n",
    "\n",
    "# 결과를 DataFrame으로 변환합니다.\n",
    "negative_samples_df = pd.DataFrame(negative_samples, columns=['resume_seq', 'recruitment_seq_negatives'])\n",
    "\n",
    "# 결과를 확인합니다.\n",
    "negative_samples_df.sort_values(by=['resume_seq'], inplace=True)\n",
    "negative_samples_df.reset_index(drop=True, inplace=True)\n",
    "negative_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정값 데이터프레임\n",
    "data = {'resume_seq': list(resume_to_recruitments.keys()), 'recruitment_seq_positives': [list(val) for val in resume_to_recruitments.values()]}\n",
    "positive_samples_df = pd.DataFrame(data, columns=['resume_seq', 'recruitment_seq_positives'])\n",
    "positive_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 만들기 위한 explode 및 labeling\n",
    "positive_pairs_df = positive_samples_df.explode('recruitment_seq_positives').rename(columns={'recruitment_seq_positives': 'recruitment_seq'})\n",
    "negative_pairs_df = negative_samples_df.explode('recruitment_seq_negatives').rename(columns={'recruitment_seq_negatives': 'recruitment_seq'})\n",
    "\n",
    "positive_pairs_df['label'] = 1\n",
    "negative_pairs_df['label'] = 0\n",
    "\n",
    "# neg_sample 포함된 상관관계 데이터프레임 형성\n",
    "all_pairs_df = pd.concat([positive_pairs_df, negative_pairs_df], ignore_index=True)\n",
    "\n",
    "all_pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이력서, 공고 메타데이터와 병합\n",
    "combined_features_df = all_pairs_df.merge(resume_data, on='resume_seq', how='left')\n",
    "combined_features_df = combined_features_df.merge(recruitment_data, on='recruitment_seq', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_df.sort_values(by='resume_seq', inplace=True)\n",
    "combined_features_df.reset_index(drop=True, inplace=True)\n",
    "combined_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이력서별로 그룹화하여 긍정적인 샘플과 부정적인 샘플을 분리\n",
    "grouped = combined_features_df.groupby('resume_seq')\n",
    "\n",
    "train_data = []\n",
    "validation_data = []\n",
    "\n",
    "# 각 이력서에 대해 반복\n",
    "for resume_seq, group in grouped:\n",
    "    # 긍정적인 샘플과 부정적인 샘플 분리\n",
    "    positive_samples = group[group['label'] == 1]\n",
    "    negative_samples = group[group['label'] == 0]\n",
    "    \n",
    "    # 긍정적인 샘플과 부정적인 샘플에서 무작위로 하나씩 선택\n",
    "    if not positive_samples.empty:\n",
    "        validation_positive_sample = positive_samples.sample(n=1)\n",
    "        train_data.append(positive_samples.drop(validation_positive_sample.index))\n",
    "        validation_data.append(validation_positive_sample)\n",
    "    \n",
    "    if not negative_samples.empty:\n",
    "        validation_negative_sample = negative_samples.sample(n=1)\n",
    "        train_data.append(negative_samples.drop(validation_negative_sample.index))\n",
    "        validation_data.append(validation_negative_sample)\n",
    "\n",
    "# 학습 데이터와 검증 데이터를 데이터프레임으로 변환\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "validation_df = pd.concat(validation_data, ignore_index=True)\n",
    "\n",
    "# 결과 확인\n",
    "(train_df.shape, validation_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_libsvm(df, label_column):\n",
    "#     libsvm_data = []\n",
    "    \n",
    "#     # Iterate over each row and create a string in libSVM format\n",
    "#     for index, row in df.iterrows():\n",
    "#         # Start with the label\n",
    "#         libsvm_row = [str(int(row[label_column]))]\n",
    "        \n",
    "#         # Add each feature:value pair\n",
    "#         for i, value in enumerate(row.drop(label_column), start=1):\n",
    "#             if value != 0:  # Only non-zero values need to be included in libSVM format\n",
    "#                 libsvm_row.append(f\"{i}:{value}\")\n",
    "        \n",
    "#         # Join all items in the row with a space and add to the list\n",
    "#         libsvm_data.append(' '.join(libsvm_row))\n",
    "    \n",
    "#     return libsvm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libsvm_train_data = convert_to_libsvm(train_df, 'label')\n",
    "# libsvm_validation_data = convert_to_libsvm(validation_df, 'label')\n",
    "# libsvm_test_data = convert_to_libsvm(combined_features_df, 'label')\n",
    "\n",
    "# # Save the libSVM data to a text file\n",
    "# with open('train.txt', 'w') as f:\n",
    "#     for item in libsvm_train_data:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('validation.txt', 'w') as f:\n",
    "#     for item in libsvm_validation_data:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('test.txt', 'w') as f:\n",
    "#     for item in libsvm_test_data:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'train.txt'\n",
    "valid_file_path = 'validation.txt'\n",
    "test_file_path = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 변환된 libSVM 데이터를 파일에서 다시 읽기\n",
    "# with open('validation.txt', 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "\n",
    "# # 각 줄을 검사하여 비정상적인 형식을 찾기\n",
    "# for line_number, line in enumerate(lines, start=1):\n",
    "#     elements = line.strip().split(' ')\n",
    "#     # 라벨 확인 (첫 번째 요소)\n",
    "#     try:\n",
    "#         label = int(elements[0])\n",
    "#     except ValueError:\n",
    "#         print(f\"Line {line_number} has invalid label: {elements[0]}\")\n",
    "#         continue\n",
    "#     # 특성 확인 (이후 요소)\n",
    "#     for element in elements[1:]:\n",
    "#         try:\n",
    "#             index, value = element.split(':')\n",
    "#             index = int(index)  # 여기서 실패할 경우 아래 print문 실행\n",
    "#             value = float(value)  # 값이 실수일 수 있으므로 float 변환 시도\n",
    "#         except ValueError:\n",
    "#             print(f\"Line {line_number} has invalid feature format: {element}\")\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FactorizationMachine(k=50,\n",
    "                          lr=0.001,\n",
    "                          l2_reg=True,\n",
    "                          l2_lambda=0.2,\n",
    "                          epoch=200,\n",
    "                          early_stop_window=3,\n",
    "                          train_data=train_file_path,\n",
    "                          valid_data=valid_file_path)\n",
    "\n",
    "fm.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
